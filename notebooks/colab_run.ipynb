{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FI-2010 Price Sensitivity Prediction\n",
        "\n",
        "This notebook runs the complete pipeline on Google Colab or locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository (if running on Colab) or navigate to project root\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "if 'COLAB_GPU' in os.environ or 'COLAB_RELEASE_TAG' in os.environ:\n",
        "    # Running on Colab - clone if needed\n",
        "    if not Path('src').exists():\n",
        "        print(\"Clone your repo here or upload files\")\n",
        "        # !git clone https://github.com/YOUR_USERNAME/fi2010-prediction.git\n",
        "        # %cd fi2010-prediction\n",
        "else:\n",
        "    # Local: navigate to project root if in notebooks folder\n",
        "    if Path('../src').exists():\n",
        "        os.chdir('..')\n",
        "    print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q numpy pandas scikit-learn xgboost torch pyyaml mlflow matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify project structure\n",
        "!ls -la\n",
        "print(\"\\n--- src/ ---\")\n",
        "!ls -la src/\n",
        "print(\"\\n--- configs/ ---\")\n",
        "!ls -la configs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Data\n",
        "\n",
        "Upload FI-2010 dataset files to `data/raw/fi2010/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data directory\n",
        "!mkdir -p data/raw/fi2010\n",
        "\n",
        "# On Colab: upload files manually or use Google Drive\n",
        "# Uncomment to upload from local machine:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for fname in uploaded.keys():\n",
        "#     import shutil\n",
        "#     shutil.move(fname, f\"data/raw/fi2010/{fname}\")\n",
        "\n",
        "# Alternative: Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp /content/drive/MyDrive/fi2010_data/*.txt data/raw/fi2010/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data files are present\n",
        "!ls -la data/raw/fi2010/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Training Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run XGBoost regression\n",
        "!python -m src.train --config configs/xgboost_reg.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run LSTM regression\n",
        "!python -m src.train --config configs/lstm_reg.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Find and display results\n",
        "outputs_dir = Path('outputs')\n",
        "if outputs_dir.exists():\n",
        "    for exp_dir in sorted(outputs_dir.iterdir()):\n",
        "        if exp_dir.is_dir():\n",
        "            for run_dir in sorted(exp_dir.iterdir()):\n",
        "                metrics_file = run_dir / 'metrics.json'\n",
        "                if metrics_file.exists():\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"Experiment: {exp_dir.name}\")\n",
        "                    print(f\"Run: {run_dir.name}\")\n",
        "                    print(f\"{'='*60}\")\n",
        "                    with open(metrics_file) as f:\n",
        "                        metrics = json.load(f)\n",
        "                    for k, v in metrics.items():\n",
        "                        if isinstance(v, float):\n",
        "                            print(f\"  {k}: {v:.6f}\")\n",
        "                        else:\n",
        "                            print(f\"  {k}: {v}\")\n",
        "else:\n",
        "    print(\"No outputs found. Run training first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display plots\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "outputs_dir = Path('outputs')\n",
        "if outputs_dir.exists():\n",
        "    png_files = list(outputs_dir.rglob('*.png'))\n",
        "    if png_files:\n",
        "        for png_file in png_files:\n",
        "            print(f\"\\n{png_file.relative_to(outputs_dir)}\")\n",
        "            display(Image(filename=str(png_file), width=600))\n",
        "    else:\n",
        "        print(\"No plots found.\")\n",
        "else:\n",
        "    print(\"No outputs found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from pathlib import Path\n",
        "\n",
        "mlruns_path = Path('mlruns')\n",
        "if mlruns_path.exists():\n",
        "    mlflow.set_tracking_uri(f'file://{mlruns_path.absolute()}')\n",
        "    \n",
        "    for exp in mlflow.search_experiments():\n",
        "        print(f\"\\nExperiment: {exp.name}\")\n",
        "        runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
        "        if len(runs) > 0:\n",
        "            cols = ['run_id', 'status']\n",
        "            metric_cols = [c for c in runs.columns if c.startswith('metrics.')]\n",
        "            display_cols = cols + metric_cols[:5]\n",
        "            display_cols = [c for c in display_cols if c in runs.columns]\n",
        "            print(runs[display_cols].to_string())\n",
        "else:\n",
        "    print(\"No MLflow runs found. Run training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Classification Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run XGBoost classification\n",
        "!python -m src.train --config configs/xgboost_cls.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Configuration Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "custom_config = {\n",
        "    'experiment_name': 'custom_experiment',\n",
        "    'seed': 123,\n",
        "    'data': {\n",
        "        'raw_dir': './data/raw/fi2010',\n",
        "        'processed_dir': './data/processed',\n",
        "        'file_patterns': ['*.txt', '*.csv']\n",
        "    },\n",
        "    'label': {\n",
        "        'tau': 20,\n",
        "        'task': 'regression',\n",
        "        'epsilon': 0.0002\n",
        "    },\n",
        "    'window': {\n",
        "        'lookback': 100,\n",
        "        'mode': 'sequence'\n",
        "    },\n",
        "    'split': {\n",
        "        'train_ratio': 0.70,\n",
        "        'val_ratio': 0.15,\n",
        "        'test_ratio': 0.15,\n",
        "        'purge_boundary': True\n",
        "    },\n",
        "    'normalization': {\n",
        "        'method': 'zscore'\n",
        "    },\n",
        "    'model': {\n",
        "        'name': 'gru',\n",
        "        'params': {\n",
        "            'hidden_size': 128,\n",
        "            'num_layers': 2,\n",
        "            'dropout': 0.3,\n",
        "            'bidirectional': False\n",
        "        }\n",
        "    },\n",
        "    'training': {\n",
        "        'batch_size': 128,\n",
        "        'epochs': 50,\n",
        "        'learning_rate': 0.0005,\n",
        "        'early_stopping_patience': 10,\n",
        "        'device': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('configs/custom.yaml', 'w') as f:\n",
        "    yaml.dump(custom_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"Custom config saved to configs/custom.yaml\")\n",
        "print(\"\\nConfig contents:\")\n",
        "print(yaml.dump(custom_config, default_flow_style=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run custom config (uncomment when data is available)\n",
        "# !python -m src.train --config configs/custom.yaml"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
